[강의자료 (ppt)](https://www.slideshare.net/TerryTaewoongUm/deep-learning-machine-learning-tutorial-for-beginners)

# Muchine Learning & Deep Learing

1. 영어공부 하세요

2. Andrew Ng , Deeplearnig.ai / Coursera 강의 비전공자에게 가장 좋습니다

CS231n(CNNs), CS224d(RNNs)

NIPS, ICML 등.. 추천

&nbsp;

sjchoi86 / dl_튜토리얼_10weeks 추천.

후배인데 형으로 부르고 싶을 정도로 좋음

나도 가끔 참고함

&nbsp;

영어 가능 : Deep learning summer school 추천

영어 불가능 : 김성훈 교수님(네이버) 강의 추천

&nbsp;

딥러닝에서 2~3년 뒤면 낡은 지식입니다

지금 발표하는 건 2~3년 전것들 입니다

---

**Object detection**

신기.. 레이블까지 나타냄 [YOLO 영상](https://www.youtube.com/watch?v=4eIBisqx9_g)


**Object recognition**

-축구

**Sentiment classification**

-감성분석. (슬프다, 기쁘다..)

---

## Machine Learning

키-몸무게 상관관계 -> 선형회귀

나이-마라톤기록 상관관계 -> 이상한곡선 가다가내려감

but, 위 두개의 점들은 같음.

데이터는 같은데, 선이 다름.

적용해야할 모델이 다름

도메인 지식이 있으면 알겠지.. 도메인 없었으면..ㅠ

우리가 도메인을 다 알지 못하니까

모델 셀렉션을 더이상 사람이 하지 않는다

p16 오버피팅

||W||**m -> 에러허용

트레이닝 에러를 최소로 맞추는 것이 최선은 아니다.
(테스트 성능이 최선이 아니다)

우리의 목적은 트레이닝을 맞추는 것이 아니라, 테스트를 맞춰야하기 때문임

Train
Validation - for early stopping
Test - for evaluation

Validation 이 모의고사임.

모의고사가 더 잘나오다가 더 안나오면 트레이닝을 멈춤

**N-fold cross Validation**

validation 셋을 여러개로 바꿈.

절대로 오버핏이 일어나지않게 제너럴라이즈 함. 일반화하도록 함( p20)

validation 잘안된다 -> 데이터를 더 모은다.

21페이지 좋은 거

www.computervisionblog.com/2016/12/nuts???

거기 자료같음

p22 내용 잘모르겟음

minimize 목적함수 하나 더 두는것

---

라그랑지안??

---

unbalance문제

어떤 사진이 축구공 알기 위해서는 몇가지 정보만 있으면 되

근데 1000x1000 이면 피쳐가 엄청많다.

해상도 낮춰도 축구공이란걸 알 수 있다.

복잡한걸 더 추상화 추상화 해서 간단한 문제로 만든다.

옛날 : 피쳐 뽑고 돌림

요즘 : 피쳐 뭐가중요한지 모르겠고 그냥 데이터를 충분히 줘보자. 컴퓨팅파워도 충분히 줘보자

&nbsp;

**비디오의 감정 맞추는 챌린지**

-> 사람 입 가릴 때 퍼포먼스 떨어짐

그 당시 충분한 정보를 주지 못해서임

missing information을 채우기 위한 다른 방법이 없을까..

이런 연구 현재 진행되고 있다

---

문제가 정해지면 방법이 나옴

problem 포뮬레이션 ?

&nbsp;

## Deep Learning

#### 사람이 feature를 정해준다는 것은?

-> 다른 수 많은 정보를 날려버린다는 것

예전에는 이미지가 있으면

거기서 피쳐를 뽑아요

그 다음 컴퓨테이션 가능한데서 뭔가를 했다

&nbsp;

**ex) 푸들, 치킨 구분하기**

여러분이라면 구분짓기 위해서 어떠한 피쳐를 뽑으시겠어요?

- 명확한 답 안나옴

이런 간단한 것도 인간이 feature를 구분하기 쉽지 않다

feature 정하는 자체가 많은 데이터를 날려먹는 것임

**-> 사람이 feature를 정하지 않고 알고리즘에게 맞기는게 딥러닝 패러다임 이다**

데이터에서 Task 까지 가도록.

그 안의 피쳐는 알아서 뽑아지도록

데이터를 주고 레이블을 주고 돌리면 feature-set을 딥러닝은 찾아낸다

&nbsp;

딥러닝을 위해서 아래 3가지가 필요

large-data -> ImageNet
computer power -> GPU
scalable method -> DL

3가지 중 **라벨링 된 라지데이터** 모으는 것이 제일 어려움.

그냥 데이터가 아닌, 라벨링 된 데이터가 있어야 함.

but, 레이블은 사람이 함.

&nbsp;

**ImageNet Classification Challenge**

2012년 딥러닝을 사용하여 top-5 error 26% 에서 15.4% 로 떨어짐. (AlexNet)

-> 2012년 딥러닝 폭발

2015년 3% (ResNet) 수준은, 사람이 라벨링을 잘못한 것을 고려해보면 엄청 대단한 것임.

( Unsupervised learning 은 레이블 없어도 됨)

---

**Local Minimum**

웅덩이에 빠져나오지 못함.

로컬적으로 최소라서 빠져나올 수 없음. (gradient로 빠져나올 수 없음)

이런게 예전 Neural Network의 문제였음

요새는?

**데이터가 방대하기 때문에 어딘가는 샛길이 있다는거...**

랜덤하게 하면 빠져나가고 결국 global minimum에 닿게 되있다.

&nbsp;
&nbsp;

---

## Deep Learning: CNN, RNN, VAE, GAN

지도 공부 좀 하시다가 비지도로 넘어가는 거 추천합니다

RNN : 자연어, 음성인식, 음성?

현재먹거리 : 지도 (CNN, RNN)
미래먹거리 : 비지도 (VAE, GAN)

&nbsp;


**지도 학습 (CNN, RNN)**

## CNN (Convolutional Neural Networks)

filter(커널) 로 배움. (인스타 필터 등)

filter 적용시킴 (p40) -> filter가 필요없는 정보를 날림

CNN 은 filter를 배우는 것

task에 맞는 filter를 배움

개와 고양이를 비교한다

어떤 filter를 적용시키면 잘 구분시키고 못구분시키고..

filter 자체를 데이터로부터 배움

파라미터 수를 줄여준다

Task를 주고, 무슨 feature가 나오는지 역계산. 이렇게 접근해볼 수 있다.

&nbsp;

베타러닝,autoML 등은 Architecture등을 만듬

Muchine Learning들을 학습하는 또 하나를 만들자..

`Localization` : Object의 위치를 박스로 표현

`segmentation` : 박스가 아닌, 픽셀로 표현

-> 아마존 알바 사이트에서 사람들에게 픽셀을 칠하게함

사람의 노력을 들여서 레이블을 붙이면  Muchine Learning은 비슷한 것을 흉내 낼 수 있더라.

지금까지의 Muchine Learning : 인간의 능력에 비슷하게 만들자

사람들의 착각 : 사람이 할 수 없는 무언가를 해낼 수 있을 것 같다.

&nbsp;

Class만들고 바운딩박스까지. 레이블도 있어야함 트레이닝 할때
(p43)

인식만 할 수있다.

**무인 자동차 AI**

할 수 있는 것 : 저건 사람,개,아줌마 등등 **인식은 가능**
할 수 없는 것 : 나는 가도되나? 위험한 사람인가? 등등 **이해는 불가능**

인식 결과를 가지고 다음 것을 하는것은 다른 것임.

&nbsp;
&nbsp;

## RNN (Recurrent Neural Networks)

자연어처리, 음성처리

CNN 보다 복잡. -> 좀 더 많은 데이터가 필요

**gate unit** 을 둠. 이전의 input이 너무 작아지거나(수렴) 너무 커지는것(발산)을 방지

어떤 정보를 넘기거나 막고 등등을 수행하는 스위치 작동함

데이터, 레이블 넣고 학습하는거임.

node 안에 스위치가 있음

&nbsp;

sequence -> 템퍼럴한 연결 (시간에 따른게 하나 더 있다.) 그래서 데이터가 더 필요함. 

그런데, 단계가 지나갈수록 별로 중요하지 않은 것은 0에 수렴하고, 중요한 것은 발산하는 버리는 경향이 있음. 

이 이슈를 gate를 이용하여 해결한다. 그정도로 알아두시면대여

https://karpathy.github.io/2015/05/21/rnn-effectiveness

2013,4 년에 했던 세익스피어 문체를 만들어내라 이런것들이 RNN 사용한 것

&nbsp;
&nbsp;

**비지도 학습 (VAE, GAN)**

**왜 우리는 비지도학습을 해야하지?** 를 알아가시면 좋을것같아요

&nbsp;

한 사람의 여러가지 표정에 대한 픽셀 변화

-> 어떤 사람인지 인식하는데 아무 쓸모없음

CNN 은 이걸 무시하는 방향으로 피쳐를 뽑아냄

감정을 분류하려면 표정들에 대한 것으로 피쳐를 뽑아냄.

그러면 그 피쳐들로 사람을 인식하는 데에는 쓸 수 없음.

그런데 인간은 그런식으로 안함.

그냥 딱 보고 전반적으로 안다.

레이블을 주면 이렇게 못함. 그 테스크에 맞게 배우기 때문임.

레이블을 주지 않고 점점 더 좋은 스페이스를 찾아가는거..

&nbsp;

좋은거란 뭐냐?

옷을 정리했는데 p55 처럼 깔끔하게 정리됨

데이터를 줬을 때, 피쳐가 이런식으로 정리가 되있는거

지도학습은 오른쪽사진(지저분) 처럼 -> 다른 task에 적용시키지 못함.

왼쪽은 여러가지 Task에 다 작용시킬 수 있음.

**레이블이 없으면 뭘 학습하지??**

&nbsp;

### ( AE (AutoEncoder) )

**셀프레이블** 을 가지고 supervised로 바꾸는거죠

p58

인풋으로 사진넣고, 아웃풋으로 **같은 사진** 을 넣는다.

100만 -> 1000 -> 100만

인코딩(압축), 디코딩 해서

찾는다.

&nbsp;

## VAE (Variational AutoEncoder)

데이터가 걔네끼리 뭉친다는 거에요.

이걸로 뭘 할 수 있을까?

내가 정우성으로 점점 변하는 이미지

음악의 풍을 바꿔보면서 새로운 노래를 만드는..

사진도 자연스럽게 부드럽게 바뀌고

음악도 자연스럽게 바뀌고

이런식으로 공간을 만들수 있다는거죠

&nbsp;

## GAN (Generative Adversarial networks)

GAN은 Distribution 만드는거에 관심이 없어요

진짜 같은 fake를 만듬.

GAN도 비지도를 지도로 바꿈

어떻게?

제너레이터 : 가짜를 만듬

폴리스 : 가짜 진짜 판별

&nbsp;

GAN은 Learning Model이 2개다

제너레이터 : 가짜 잘 만들게 잘하게 학습시킴

폴리스 : 가짜 잘 판별하게 잘하게 학습시킴

&nbsp;

경쟁을 계속 하다보면 어디에 닿음

그 때 좋은게 나옴

어떻게 하면 둘 다 엄청 뛰어난 루팡과 홈즈를 만들수있을까?

실력 두 개를 적절하게 맞춰가면서 성장 시켜야 함

어느 한 쪽이 뛰어나면 다른 쪽 트레이닝 어려움

초창기: 무너진얼굴, 작년 초 : 진짜처럼 만듬, DRAGAN : 더진짜같음

&nbsp;

if 진짜 같은 샘플을 얻고 싶다

-> GAN을 이용하면 좋아요

그래서 사람들이 GAN을 굉장히 좋아해요

XYX 사진에서 고흐풍 그림을 갔다가 와요 도쿄풍을 갔다가와요. 갔다 왔을 때 진짜 가짜인지 구분 잘 해야 되고 도메인 구분 잘 해야 되고..

&nbsp;

**GAN을 여러가지 활용 가능해요**

그 중 하나가 **CYCLE-GAN**인데요

말이 움직이는 영상을 얼룩말로 바꿀 수 있는거죠

여러가지 굉장히 많아요

흑백 사진에 칼라를 입혔을 때, 진짜 처럼 만들 수 있어요

하루 하루 사이에 새로운 GAN들이 많이 나와요

GAN VARIANTS 굉장히 많음

사람들이 AI에서 우와~ 하는 것들 대부분 GAN 일거에요

&nbsp;

Youtube 영상 보여줌

* Auto ~? / 책읽어주는 딥러닝-> 손석희, 문재인

* GOogle Duplex : AI Assistant Calls Local Businesses To Make Appointments

궁금한건 질문하고.. 필요한 정보 채우고..

&nbsp;
&nbsp;

---

## Can we believe DNNs?

### 1. Adversarial attacks

**무인자동차** 가 인식하죠.

신호등 : 초록불이다.

이 초록불을 받아들여야하는가?

신뢰도 95%인데, 5% miss 를 어떻게 받아들여야 할까?

&nbsp;

p80. 여자사진6개

원본과의 픽셀 distance가 다 똑같아요. 화질이 더 좋을 수도, 뭉갤수도 있어요

distance는 분명히 같은데, 사진이 다 달라요.

&nbsp;

우리가 생각하는 AI의 방향과 실제 AI의 방향이 불일치할 때 문제가 생겨요

매치가 안되는 순간 어이가 없는 에러가 발생하는거죠

자전거 발견하지 못해서 사망자 발생 등등

좋은 성능도 중요하겠지만, 인간의 생각과 비슷하게 가야되요.

&nbsp;

p81 팬더

팬더에 특정 노이즈를 주었더니 타조처럼 보일수가 있어요

&nbsp;

Stop 신호를 보이는 건 Stop이지만, AI가 Go로 인식하게끔 만들 수 있어요.

(사람눈엔 Stop인데 AI에겐 Go로 인식하게 노이즈를 줄 수 있음)

이를 악의적으로 사용할 수가 있어요

&nbsp;

p82

도서관 사진 2개 있음

사람눈엔 똑같아 보임.

그런데 오른쪽 사진은 prison으로 인식함.

&nbsp;

이처럼, 새로운 형태의 테러리즘을 생각해봐야 함.

우리는 AI를 잘 믿고 있는데, 예상치 못한 위험한 상황이 발생할 수 있음.

&nbsp;

p83 바나나

바나나 있음. (바나나로 인식)

바나나 옆에 토스트기 갖다놈. (바나나로 인식, 토스트기 조금 올라감)

바나나 옆에 어떤 patch를 갖다놈. (토스터기로 인식)

&nbsp;

강도의 생각 : 'cctv가 날 감시하는 것 같아.'

그럼 patch를 붙여서 다른 사람처럼 인식되게 해야지~ 영화에서 페이스오프 하는 것 처럼

&nbsp;

사람의 인식, 알고리즘 인식이 서로 달라서 문제가 생김

-> 인풋 스페이스가 꺼지는 큰 변화가 생김. 이 변화가 안되게 다시 트레이닝 시켜야한다는 이런 이슈가 있음

&nbsp;

### 2. Uncertainty

바나나인데 토스터할때, 헷갈려... uncertainty를 어떻게 줄 수 있을까

가우시안 프로세스 불라불라..

드롭아웃.

퍼포먼스에 랜덤하게 가렸을 때도 잘나오게 한다면 ? -> 노이즈에 저항가능

이걸 uncertainty에도 쓰임.

바나나가 휙 떨어져. 그 샘플주변에 평탄이 아닌 함정하나가 푹 있다는거. 그런방법중하나가 드롭아웃..

음..

&nbsp;

### 3. Interpretability

개 사진.

다른덴 가려도 상관없는데, 개 얼굴을 가리니 개인 줄 모른다.

-> 이 AI는 얼굴을 주목하구나!

input에 어떤것을 어텐션 주느냐

근거를 visualization 할 수가 있다.

greenlight 근거가 초점이 이상한데 가있으면 이상한거임

`mirror in lake` 하면 어텐션 보는거죠

AI는 mirror in lake라고 대답 했는데, 뭘 보고 그런거냐?

파워풀 해 보이지만, 실수를 저지를 수 있음

이걸 얘가 실수한 것인지, 믿어도 되는지 구분할 수 있어야함

&nbsp;

테러, 보안, 윤리문제들..

위 단락의 핵심은 **Noise** 에요.

**Noise** 로 장난칠 수 있다는거죠

**Noise** 가지고 어디 주목하는지도 알 수가 있죠
